{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMR1rtKv0bp3Bcvmze85ger",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShubhMody/Tensorflow-Developer-Certification-Prep/blob/main/04_Transfer_Learning_With_Tensorflow_Part_1_Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04. Transfer Learning with TensorFlow Part 1: Feature Extraction\n",
        "\n",
        "There are two main benefits to using transfer learning:\n",
        "1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\n",
        "2. Can leverage a working neural network architecture which has **already learned** patterns on similar data to our own. This often results in achieving great results with less custom data."
      ],
      "metadata": {
        "id": "RZkPPlJi-aA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#are we using a GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWb2HVS-_Vw5",
        "outputId": "5ff7cacd-efca-45b7-8905-a91a1a6f8759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading and Becoming one with data"
      ],
      "metadata": {
        "id": "hYySd8L0_idL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get data (10% of 10-food-classes from food101)\n",
        "import zipfile\n",
        "\n",
        "#download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac-eGFxp_z1g",
        "outputId": "25e18908-ca54-4a75-9415-d8ad9850dea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-10 12:56:24--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.202.128, 74.125.199.128, 172.253.117.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.202.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   135MB/s    in 1.2s    \n",
            "\n",
            "2023-07-10 12:56:25 (135 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unizp the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "g-zPjI2RAUg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How many images in each folder?\n",
        "import os\n",
        "\n",
        "#walk through 10 percent data directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'. \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3rbP2cWAnI2",
        "outputId": "4a7173b9-a3d7-4235-9101-b59f39eed2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'. \n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'. \n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Data Loaders"
      ],
      "metadata": {
        "id": "oCCdJIVEBvZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "print(\"Training Images\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size = IMAGE_SHAPE,\n",
        "                                                          batch_size = BATCH_SIZE,\n",
        "                                                          class_mode = \"categorical\")\n",
        "\n",
        "print(\"Testing Images\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size = IMAGE_SHAPE,\n",
        "                                             batch_size = BATCH_SIZE,\n",
        "                                             class_mode = \"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SUk3Ta5PRRW",
        "outputId": "2490fefc-6798-4815-e7d0-de145e3babcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Images\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing Images\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up Callbacks"
      ],
      "metadata": {
        "id": "i253CXmGQsZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks are extra functionality you can add to your models to be performed during or after training. Some of the most popular callbacks include:\n",
        "\n",
        "* **Experiment tracking with TensorBoard** - log the performance of multiple models and then view and compare these models in a visual way on TensorBoard (a dashboard for inspecting neural network parameters). Helpful to compare the results of different models on your data.\n",
        "* **Model checkpointing** - save your model as it trains so you can stop training if needed and come back to continue off where you left. Helpful if training takes a long time and can't be done in one sitting.\n",
        "* **Early stopping** - leave your model training for an arbitrary amount of time and have it stop training automatically when it ceases to improve. Helpful when you've got a large dataset and don't know how long training will take."
      ],
      "metadata": {
        "id": "pNyBwBE_qRQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create TensorBoard callback (We need to functionize it because we need new one for each model)\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "\n"
      ],
      "metadata": {
        "id": "VvB2w11ZqnS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Models using TensorFlow Hub\n",
        "In the past we've used TensorFlow to create our own models layer by layer from scratch.\n",
        "\n",
        "Now we're going to do a similar process, except the majority of our model's layers are going to come from TensorFlow Hub.\n",
        "\n",
        "In fact, we're going to use two models from TensorFlow Hub:\n",
        "\n",
        "1. ResNetV2 - a state of the art computer vision model architecture from 2016.\n",
        "2. EfficientNet - a state of the art computer vision architecture from 2019.\n",
        "\n",
        "State of the art means that at some point, both of these models have achieved the lowest error rate on ImageNet (ILSVRC-2012-CLS), the gold standard of computer vision benchmarks.\n",
        "\n",
        "You might be wondering, how do you find these models on TensorFlow Hub?\n",
        "\n",
        "Here are the steps I took:\n",
        "\n",
        "1. Go to tfhub.dev.\n",
        "2. Choose your problem domain, e.g. \"Image\" (we're using food images).\n",
        "3. Select your TF version, which in our case is TF2.\n",
        "4. Remove all \"Problem domanin\" filters except for the problem you're working on.\n",
        "\n",
        "Note: \"Image feature vector\" can be used alongside almost any problem, we'll get to this soon.\n",
        "The models listed are all models which could potentially be used for your problem.\n"
      ],
      "metadata": {
        "id": "Hi1cntt2DWAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets compare the following 2 models\n",
        "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
        "\n",
        "efficientnet_url = \"https://tfhub.dev/google/efficientnet/b0/feature-vector/1\""
      ],
      "metadata": {
        "id": "3jdDXXneDeUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import dependencies\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "IeNEDv3yI6VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets make a create_model() function to create a model from a url\n",
        "def create_model(model_url, num_classes = 10):\n",
        "  \"\"\"Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "\n",
        "  Args:\n",
        "    model_url (str): A TensorFlow Hub feature extraction URL.\n",
        "    num_classes (int): Number of output neurons in output layer,\n",
        "      should be equal to number of target classes, default 10.\n",
        "\n",
        "  Returns:\n",
        "    An uncompiled Keras Sequential model with model_url as feature\n",
        "    extractor layer and Dense output layer with num_classes outputs.\n",
        "  \"\"\"\n",
        "\n",
        "  # Download the pretrained model and save it as a Keras layer\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                            trainable = False,\n",
        "                                            name = \"feature_extraction_layer\",\n",
        "                                            input_shape = IMAGE_SHAPE+(3,))\n",
        "\n",
        "  #Create our own model\n",
        "  model = tf.keras.Sequential([\n",
        "      feature_extractor_layer,\n",
        "      layers.Dense(num_classes, activation = \"softmax\", name = \"output_layer\")\n",
        "\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "N4vvaagJJTTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating ResNet TensorFlow hub feature extraction Model\n"
      ],
      "metadata": {
        "id": "6OWCBu8ALBQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create ResNet model\n",
        "\n",
        "resnet_model = create_model(resnet_url,\n",
        "                            num_classes = train_data_10_percent.num_classes)"
      ],
      "metadata": {
        "id": "TJzMOXBLLO0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.compile(loss = \"categorical_crossentropy\",\n",
        "                     optimizer = tf.keras.optimizers.Adam(),\n",
        "                     metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "qoV6oKrfMymJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDMk_04ZaJ6w",
        "outputId": "0392bc4e-cfff-438d-ed83-45a91f23d153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extraction_layer (K  (None, 2048)             23564800  \n",
            " erasLayer)                                                      \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_history = resnet_model.fit(train_data_10_percent,\n",
        "                                  epochs=5,\n",
        "                                  steps_per_epoch=len(train_data_10_percent),\n",
        "                                  validation_data=test_data,\n",
        "                                  validation_steps=len(test_data),\n",
        "                                  # Add TensorBoard callback to model (callbacks parameter takes a list)\n",
        "                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\", # save experiment logs here\n",
        "                                                                         experiment_name=\"resnet50V2\")]) # name of log files\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "RZlHwVFce0y6",
        "outputId": "c02e6707-7385-4faf-c245-e95518337fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorflow_hub/resnet50V2/20230710-125639\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 574s 24s/step - loss: 1.9890 - accuracy: 0.3400 - val_loss: 1.2285 - val_accuracy: 0.5984\n",
            "Epoch 2/5\n",
            "13/24 [===============>..............] - ETA: 58s - loss: 0.9967 - accuracy: 0.7136 "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-35ba6214559a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m resnet_history = resnet_model.fit(train_data_10_percent,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                   \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_10_percent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets Create a function to plot our loss curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#plot validation and training curves\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns seperate loss curves for training and validation metrics\n",
        "\n",
        "  Args:\n",
        "    history: tensorflow history object\n",
        "\n",
        "  Returns:\n",
        "    plots of training/validation loss and accuracy metrics.\n",
        "\n",
        "  \"\"\"\n",
        "  loss = history.history[\"loss\"]\n",
        "  val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "  accuracy = history.history[\"accuracy\"]\n",
        "  val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "  epochs = range(len(history.history[\"loss\"]))\n",
        "\n",
        "  #plot loss\n",
        "  plt.plot(epochs, loss, label = \"training loss\")\n",
        "  plt.plot(epochs, val_loss, label = \"validation_loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel('epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  #plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label = \"training accuracy\")\n",
        "  plt.plot(epochs, val_accuracy, label = \"validation accuracy\")\n",
        "  plt.title(\"Accuracy\")\n",
        "  plt.xlabel('epochs')\n",
        "  plt.legend();"
      ],
      "metadata": {
        "id": "Qdz9ZiXqbJYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(resnet_history)"
      ],
      "metadata": {
        "id": "YRywYtcAmsUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating EfficientNetB0 TensorFlow hub feature extraction Model"
      ],
      "metadata": {
        "id": "-qmr4JI-mxv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model = create_model(model_url = efficientnet_url,\n",
        "                                  num_classes = train_data_10_percent.num_classes)\n",
        "\n",
        "#Compile efficientnet model\n",
        "efficientnet_model.compile(loss = \"categorical_crossentropy\",\n",
        "                           optimizer = tf.keras.optimizers.Adam(),\n",
        "                           metrics = [\"accuracy\"])\n",
        "\n",
        "#Fit the model\n",
        "efficientnet_history = efficientnet_model.fit(train_data_10_percent,\n",
        "                                              epochs = 5,\n",
        "                                              steps_per_epoch = len(train_data_10_percent),\n",
        "                                              validation_data = test_data,\n",
        "                                              validation_steps = len(test_data),\n",
        "                                              callbacks = [create_tensorboard_callback(dir_name = \"tensorflow_hub\",\n",
        "                                                                                       experiment_name = \"efficientnetb0\")])"
      ],
      "metadata": {
        "id": "A6nO_4w2nQAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(efficientnet_history)"
      ],
      "metadata": {
        "id": "Mp1yxFkop1o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing models using TensorBoard"
      ],
      "metadata": {
        "id": "7nb9hX1-qTT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload tensorboard dev records\n",
        "!tensorboard dev upload --logdir ./tensorflow_hub/ \\\n",
        "  --name \"EfficientNetB0 vs ResNet50V2\" \\\n",
        "  --description \"Comparing two different TF hub feature extraction model architecture using 10% of training data\" \\\n",
        "  --one_shot"
      ],
      "metadata": {
        "id": "yM2Ir9Ah2z5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u7rply4e38yy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}